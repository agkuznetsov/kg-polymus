<p>В 1970-е годы начинает активно развиваться биоэтика. Биоэтика - это междисциплинарное поле исследовании философских, богословских, морально-этических, правовых и прочих проблем, возникающих в контексте интенсивного развития биомедицинской науки и применения в здравоохранении высоких технологий. Развитие биоэтики во многих странах мира способствовало тому, что проблемы информированного согласия, врачебной тайны, аборта, применения современных методов контрацепции, суррогатного материнства, определения смерти в связи с диагнозом «смерть мозга», эвтаназии, усовершенствования человека и др. стали предметом пристального внимания как ученых, так и обычных граждан, испытывающих все более сильное влияние науки на их жизнь. Концептуальным каркасом биоэтики стали выделенные Томом Бичампом и Джеймсом Чилдрессом четыре основополагающих принципа - уважение автономии личности, непричинение вреда, благодеяние, справедливость. Принцип уважения автономии пациента, заложенный в каркас биоэтики, находясь в противоречии с традиционным медицинским патернализмом, заложенным Гиппократом, выдвинул в качестве приоритета защиту прав пациента, тогда как раньше пациент должен был беспрекословно подчиняться авторитету врача, исключавшему больного из процесса принятия решений, касающихся его или ее здоровья. Принципы биоэтики и способы решения ее проблем повлияли на становление норм международного права.</p><p>В XXI веке ученых и общество стали волновать этические проблемы развития конвергентных (нано-био-инфо-когнитивных) технологий, робототехники, нанонауки, искусственного интеллекта и других направлений развития науки и техники. Активно развивается экологическая этика. В свете успехов генетических технологий особенно актуальным становится обсуждение морального статуса эмбриона и проблем, связанных с генетическими экспериментами и созданием новых форм жизни.</p><p>Базовые понятия</p><p>Биоэтика</p><p>Проблемы биоэтики касаются использования медицинских технологий и результатов научных исследований для вмешательства в человеческий организм. Поэтому в первую очередь с ними сталкиваются ученые, работающие в области биологических и медицинских наук. В результате стремительного развития технологической базы медицины и биологии и развития генетики у врачей появились научно обоснованные методы вмешательства в человеческий организм и влияние на здоровье, которые поставили вопрос о том, где проходит граница власти врача над пациентом и власти ученого решать, какие исследования допустимы. Кроме того, начиная с 1970-х годов существенно изменился общественный климат: начали появляться общественные группы и движения, которые боролись за право более активного участия граждан в принятии решений, касающихся медицины, здравоохранения и связанных с ними научных исследований.</p><p>К числу наиболее известных и сложных биоэтических проблем относятся проблемы клонирования, биотехнологического улучшения человека, генной инженерии, пересадки органов, суррогатного материнства, критериев смерти, эвтаназии. Хорошей иллюстрацией того, насколько сильно изменилось общественное отношение к вопросам, касающимся научных исследований в области биологии и медицины, является клонирование. Клонирование означает создание генетически идентичных организмов. Клонирование встречается в природе, например среди растений, использующие бесполое размножение. Человеческие близнецы тоже являются клонами. Однако после клонирования овечки Долли в 1996 году при помощи технологии пересадки ядер соматических клеток стало понятно, что существуют и будут развиваться технологии, позволяющие целенаправленно клонировать людей. Эта ситуация поставила много новых этических вопросов. Сегодня существуют возможности для осуществления двух типов клонирования людей: репродуктивного клонирования, предполагающего выращивание человеческого эмбриона в лабораторных условиях для последующей имплантации его в матку, и терапевтического клонирования, заключающегося в лабораторном выращивании эмбрионов с целью проведения на них исследований или получения стволовых клеток. Однако оба способа вызывают массу возражений и в ряде стран запрещены на законодательно уровне. Это означает, что научные исследования ставят новые этические вопросы, обсуждение которых выходит далеко за рамки научного сообщества.</p><p>Проблема клонирования, как и остальные проблемы биоэтики, указывает на несколько важнейших этических вопросов, которые приходится решать ученым и общественности в связи с развитием современных биологических и медицинских знаний и технологий. Во-первых, возникает вопрос о проведении границы между естественным и искусственным. Для многих клонирование людей, искусственное оплодотворение, генная инженерия являются морально недопустимыми, поскольку это искусственные способы вмешательства в естественные процессы. Однако выведение новых сортов растений и животных тоже является искусственным вмешательством. Кроме того, аргумент о том, что ученые, производящие соответствующие вмешательства, тем самым нарушают законы природы, логически непоследователен, так как отсылает к такой концепции законов природы, согласно которой эти законы невозможно нарушить.</p><p>Во-вторых, возникает вопрос о потенциальных рисках. Каковы последствия искусственного оплодотворения, или создания генетически модифицированных бактерий, способных бороться с загрязнением окружающей среды, или употребления в пищу генетически модифицированных организмов? Это опасения могут разрешить только доказательные научные исследования, убедительно демонстрирующие отсутствие вреда от соответствующих технологий. К примеру, существующие научные данные показывают, что искусственное оплодотворение и употребление генетически модифицированных организмов не наносит никакого вреда и не повышает риск заболеваний. Однако использование других технологий связано с гораздо более неопределенными рисками, без всестороннего и исчерпывающего изучения которых эти технологии нельзя применять и распространять.</p><p>Наконец, в-третьих, многие биомедицинские исследования связаны с вопросами, касающимися того, кто должен принимать окончательное решение в отношении вмешательства в организм. Следует ли отдавать это право только ученым и врачам или, наоборот, последнее слово должно оставаться за обычными людьми, которых затрагивает предлагаемое вмешательство? Кто должен принимать решение о смерти в спорных случаях (например, в случае смерти мозга, констатация которой является сложным диагностическим вопросом)? Допустимо ли добровольное решение пациента уйти из жизни, если она или он испытывает невыносимые страдания? Можно ли использовать органы пациента после его или ее смерти без его или ее согласия? Все эти проблемы должны обсуждаться и решаться не только в кругу ученых, но обязательно с учетом их мнения.</p><p>Учитывая сложность биоэтических вопросов, с которыми сталкиваются ученые, необходимо формулирование общих принципов, на которые могут ориентироваться ученые при проведении научных исследований в области биологии и медицины. Американские исследователи Том Бичамп и Джеймс Чилдресс выделяют четыре базовых принципа биомедицинской этики</p><p>[w:footnoteReference]</p><p>: уважения автономии личности, непричинение вреда, благодеяние, справедливость. Эти принципы предполагают, что при организации исследований в области биомедицины следует учитывать интересы не только ученых, но и причастных социальных групп. Ученые не должны считать свои выводы и наблюдения само собой разумеющимися. Они должны объяснять общественности, как они их получили и каковы возможные риски.</p><p>Опыты на людях и животных</p><p>С проблемами биоэтики тесно связаны вопросы, касающиеся допустимости проведения исследований и клинических испытаний на людях и животных. Эксперименты на людях стали предметом широкого обсуждения после Второй мировой войны, когда было установлено, что на узниках нацистских концлагерей проводились жестокие научные эксперименты, часто заканчивавшиеся смертью. В 1947 году на основе решений Нюрнбергского трибунала - международного судебного процесса над руководителями гитлеровской Германии - был принят Нюрнбергский кодекс, регулирующий проведения исследований на людях. Развитием Нюрнбергского кодекса стала Хельсинкская декларация, первая редакция которой была подписана в 1964 году. Ключевым элементом обеих документов является принцип информированного согласия - добровольного разрешение испытуемого или его представителя на участие в исследовании, основанное на полной информации о целях и процедуре исследования, возможных последствиях, разных способах проведения исследования. Данный принцип предполагает, что интересы испытуемого первичны по отношению к интересам ученого.</p><p>Опыты на животных пока не регулируются соответствующими конвенциями, однако многие ученые и общественные деятели выступают за гуманизацию отношения к животным в научных исследованиях и подчеркивают необходимость введения правил, регулирующих способы обращения с животными и определяющих, в каких типах исследований опыты на животных целесообразны, а в каких можно обойтись без них.</p><p>Ключевой вопрос, возникающий в связи с проведением научных исследований на людях, заключается в обосновании необходимости подвергнуть определенных людей риску ради пользы других людей. Люди могут принимать участие в научных исследованиях не только потому, что они ожидают получить выгоду для себя лично, но и потому, что они хотят помочь другим людям. В последнем случае потенциальный вред, который может быть нанесен человеку в ходе исследования, может не компенсироваться или компенсироваться лишь частично потенциальной пользой от исследования. В этой связи британская специалистка по биоэтике Аннетт Рид и американский специалист по биоэтике Дэвид Вендлер выделяют три типа рисков, которые должны учитываться учеными при планировании и проведении исследований на людях: абсолютные, относительные и непрямые</p><p>[w:footnoteReference]</p><p>. Абсолютные риски - это риски, возникающие, когда исследовательское вмешательство не компенсируется потенциальной клинической пользой. Абсолютные риски могут быть чистыми (когда потенциальная клиническая польза отсутствует) или смешанными (когда потенциальная клиническая польза есть, но не перевешивает возможный вред). Примером чистого абсолютного риска является биопсия печени пациента при изучении эффекта влияния определенного лекарства на рак печения или исследования, проводимые на здоровых пациентах. Пример смешанного риска - биопсия печени пациента, позволяющая не только изучить эффект лекарства, но и установить стадию, на которой находится его или ее заболевание. Относительные риски - риски, возникающие, когда польза от исследовательского вмешательства перевешивает опасность вреда, однако соотношение рисков и выгод у данного вмешательства менее благоприятное, чем соотношение рисков и выгод у альтернативных способов лечения или диагностических процедур. Например, при изучении эффектов дешевого первого поколения некоторого лекарства и дорогого второго поколения этого же лекарства соотношение рисков и выгод в первом случае менее благоприятное, чем во втором. Непрямые риски связаны с ситуациями, когда исследовательское вмешательство делает соотношение рисков и выгод параллельно применяемых процедур менее благоприятным. Например, изучение влияния экспериментального лекарства на рак печени может приводить к тому, что данное лекарство будет ухудшать соотношение рисков и выгод применения диуретиков, которые обычно принимаются при раке печени.</p><p>Проведением исследований на людях и животных занимаются, однако, не только ученые, специализирующиеся в области биологии и медицины. Людей изучают также социологи, психологии, антропологи. В конкретных дисциплинах вырабатываются свои правила проведения таких исследований и составляются этические кодексы, содержащие подробные указания относительно условий проведения исследования, информирования исследуемых, соблюдения конфиденциальности и анонимности, принципов взаимодействия с исследуемыми.</p><p>Одним из механизмов регулирования исследований на людях и животных в науке являются так называемые комитеты по этике, функционирующие в университетах и других научных учреждениях. Эти комитеты занимаются не только разрешением спорных и конфликтных ситуаций, но и проводят оценку проектов исследований. Подобные комитеты могут быть как чисто дисциплинарными, так и включающими представителей общественности, практикующих врачей, священников и специалистов по этике.</p><p>Военное использование науки</p><p>Наука тесно связана с технологическим развитием общества, и эта связь только усиливается. Однако помимо технологий, приносящих несомненную пользу обществу (хотя, безусловно, любая технология может иметь негативные эффекты, например усиливать неравенство), существуют технологии, относительно которых ведутся ожесточенные споры, затрагивающие, в том числе, науку. Речь идет, прежде всего, о технологиях военного назначения и, в частности, летальном оружии и оружии массового поражения.</p><p>Переломным моментом как во взаимоотношениях науки и государства в области разработки вооружений, так и в обсуждении этических проблем таких взаимоотношений стал Манхэттенский проект - программы по созданию ядерного оружия в США. Одним из руководителей проекта был американский физик Роберт Оппенгеймер, в лаборатории которого создавались атомные бомбы. Ученые из разных стран участвовали в проекте наравне с военным и инженерами. В рамках проекта были созданы две бомбы, позже сброшенные на Хиросиму и Нагасаки в 1945 году и унесшие жизни нескольких сотен тысяч людей. После этого события стало очевидно, что ученые не могут находится в стороне от этических вопросов, связанных с применением научных разработок для создания оружия, способного не только убивать людей, но и уничтожить человечество. В 1955 году Бертран Рассел опубликовал манифест против ядерного вооружения, подписанный рядом выдающихся ученых и интеллектуалов, включая Альберта Эйнштейна. Этот манифест лег в основу Пагуошского движения ученых (названо в честь места проведения первой конференции движения - городка Пагуош в Канаде), выступающих за предотвращение мировой термоядерной войны, за мир и безопасность на Земле.</p><p>Однако создание оружия массового поражения (ядерного, химического и биологического) - не единственная область, в которой используются разработки ученых. Совершенствование военных технологий невозможно без вклада ученых. Например, ученые могут участвовать в создании автономных роботизированных систем, способных убивать людей.</p><p>Использование результатов научных исследований для создания оружия ставит перед учеными множество этических вопросов и заставляет выбирать моральную позицию в отношении их. Одна из точек зрения состоит в том, что ученые не несут ответственности за то, как будут использоваться полученные ими данные. Если в ходе самого исследования соблюдаются базовые этические принципы (например, получение информированного согласия исследуемых), то дальнейшая судьба научных знаний не находится во власти ученых. Ученые решают фундаментальные научные задачи, а использование получаемых результатов во благо или во вред определяется вненаучными факторами (политическими, экономическими, социальными). Критики этой точки зрения указывают, что, во-первых, провести четкую грань между прикладными и фундаментальными разработками невозможно, во-вторых, что научная деятельность включает не только собственно акт исследования, но и сообщение о результатах исследования других ученым и неспециалистам, и, в-третьих, что научные исследования никогда не замкнуты от окружающего общества, как потому, что ученые являются членами общества, так и потому, что наука являются социальной практикой, к которой, помимо ученых, причастны другие общественные группы. Поэтому ученые несут определенную ответственность за то, в каких целях используется научное знание.</p><p>Этические вопросы, касающиеся связи науки и военных технологий, усложняются двумя обстоятельствами: тем, что чаще всего ученые участвуют в проектах с четко обозначенной военной миссией (ситуации, когда результаты научных исследований используют в военных целях без ведома ученых, редки), и тем, что не все военные технологии связаны с нанесение ущерба противнику (например, ученые могут помогать разрабатывать лекарства для армии, которые потом могут использоваться и в гражданской жизни). Поэтому решение вопроса о степени и форме ответственности ученых за использование получаемых ими данных в военных целях - очень непростой вопрос, который, однако, ученые должны учитывать и обсуждать. Ученый не может уклониться от ответственности за то, каким общественным целям служит научное знание.</p><p>Этические проблемы робототехники и искусственного интеллекта</p><p>Научные разработки в области искусственного интеллекта принесли множество результатов, которые сегодня находят применение в компьютерных программах, мобильной связи, компьютерных играх, робототехнике, медицине и т.д. И хотя мечта создать полный аналог человеческого интеллекта, способный ориентироваться в окружающем мире, мыслить, решать этические дилеммы, испытывать эмоции и учиться, неосуществима, ученые помогают создавать компьютерные системы, способные не только заменять людей в некоторых видах деятельности, но и принимать решения, от которых может зависеть жизнь людей. В целом человечество все больше зависит от технологий, которые становятся все менее понятными простым пользователям и все более сложными и наукоемкими. В связи с этим возникает ряд этических вопросов, касающихся распределения ответственности за действия искусственного интеллекта между машиной и человеком, способа принятия решений в система человек-машина, делегирования полномочий от человека к технике.</p><p>Со времен Айзека Азимова, который сформировал три закона робототехники (робот не может причинить вред человеку или своим бездействием допустить, чтобы человеку был причинен вред; робот должен повиноваться всем приказам, которые дает человек, кроме тех случаев, когда эти приказы противоречат Первому Закону; робот должен заботиться о своей безопасности в той мере, в которой это не противоречит Первому или Второму Законам), роботы и системы искусственного интеллекта стали повседневной реальностью, что сделало этические вопросы, связанные с их возможностями и принципами функционирования, еще более острыми. Какого рода решения может принимать искусственный интеллект? Кто и каким образом должен его контролировать? В каких областях человеческой деятельности искусственный интеллект не должен применяться? Имеют ли роботы юридические права? Как защитить право людей на личную жизнь, когда технологии становятся все более вездесущими и собирают все больше персональной информации?</p><p>Ряд ученых, например, шведский философ Ник Бостром, высказывают опасение, что достигнутый на определенном этапе уровень развития искусственного интеллекта (суперинтеллект) может представлять угрозу для будущего человечества. Цели, которые будет ставить перед собой такой суперинтеллект, могут оказаться несовместимы с человеческими ценностями и, в конечном счете, с человеческим существованием. Бостром полагает, что необходимо придерживаться стратегии дифференциального технологического развития, которая предполагает отказ от разработки технологий искусственного интеллекта, способных нанести вред человечеству, и инвестирование в разработку технологий, которые будут приносить пользу и защищать от вредоносных технологий. Многие современные разработки в области искусственного интеллекта (вроде создания автономных автомобилей) способны принести огромную пользу человечеству, однако необходим постоянный контроль за их развитием. Одно из направлений исследований в данной области - решение вопроса о том, каким образом можно научить искусственный интеллект придерживаться человеческих этических принципов, которые крайне сложно кодифицировать.</p><p>По мнению Бострома и других специалистов по искусственному интеллекту, при создании искусственного интеллекта и роботизированных систем необходимо придерживаться ряда принципов, которое позволят контролировать создаваемые системы</p><p>[w:footnoteReference]</p><p>. Во-первых, системы искусственного интеллекта должны быть «прозрачными», т.е. их принципы функционирования должны быть известны их создателям и должна существовать возможность эти принципы установить. Во-вторых, искусственный интеллект должен быть предсказуемым. Те, кто управляет соответствующими системами, должны знать, на что эти системы способы и какие цели они могут преследовать. Поведение таких система должно быть ожидаемым. В-третьих, искусственный интеллект должен быть защищен от манипуляций. Системы искусственного интеллекта должна быть безопасными и устойчивыми в отношении попыток обмануть их или изменить их таким образом, чтобы они решали не те задачи, для которых предназначены.</p><p>Человечество находится только в начале пути тесного сосуществования с искусственным интеллектом, однако ученые должны уже сейчас задумываться об этических последствиях их исследований и разработок в данной области.</p><p>Экологические проблемы</p><p>Научные исследования могут приводить к созданию технологий, способных наносить вред окружающей среде - тезис, который иллюстрируется множеством примером, одним из наиболее трагических среди которых является авария на Чернобыльской атомной электростанции. В той мере, в какой технологии, наносящие вред окружающей среде, основываются на данных научных исследований, ученые несут ответственность за экологические проблемы, с которыми сталкиваются сегодня отдельные государства и все человечество в целом. Но они же могут помочь в их решении. К примеру, ученые установили, что происходящие сегодня на планете климатические изменения, угрожающие будущему Земли, носят антропогенный характер. Для координации действий ученых и распространения научно обоснованных данных о состоянии климата в 1988 году была создана Межправительственная группа экспертов по изменению климата. Эта организация не проводит собственных исследований, однако привлекает ученых для составления и рецензирования отчетов, основанных на анализе существующей научной литературы.</p><p>Решение других экологических проблем тоже невозможно без участия ученых. Ученые вносят значительный вклад в области альтернативной энергетики, создания экологически безопасных материалов, утилизации отходов, сохранения биологического разнообразия, восстановления экосистем и ландшафтов, очистки воды и почв. Ученые могут моделировать различные сценарии развития экосистем, тем самым определяя направления экологической политики.</p><p>Развитие экологического сознания в современных обществах было связано с отказом от принципа антропоцентризма, главенствовавшего в экологической этике до середины XX века. Согласно этому принципу, человек занимает верховное место в природе и поэтому может использовать любые средства для своего выживания и развития. Поэтому человек уничтожал целые виды животных, менял природные ландшафты, загрязнял окружающий мир. Изменение антропоцентрических представлений было обусловлено рядом критических и экологических движений, которые исходили из того, что человек не обладает моральным превосходством над другими видами животных и должен нести ответственность за состояние Земли. Наиболее радикальные версии антиантропоцентризма предлагают наделять других животных и даже неживые объекты равными с человеком правами, в том числе - юридическими.</p><p>Другой дихотомией, которая характеризует современную экологическую этику, является различение индивидуализм/холизм. Многие современные экологические движения исходят из того, что моральным статусом обладают не только отдельные индивиды (как люди, так и животные), но и сообщества или группы. Данная точка зрения поддерживается научными исследованиями, которые показывают, в природе группы не представляют собой простую сумму отдельных индивидов, а являются самостоятельными целостностями, которые необходимо рассматривать в качестве действующих единиц. Независимо от того, приписываются ли этим целостностям качества, подобные качествам отдельных индивидов, их можно наделять моральным статусом. Более радикальная версия такой холистской интерпретации экологической этики предполагает, что целостности или сообщества, частью которых выступают отдельные люди или особи, включают не только живых существ, но и растения, реки, годы и другие элементы экосистем. В конечном счете каждая экосистема является целостной единицей, как и вся планета целиком.</p><p>Одной из наиболее известных и широко распространенных система принципов, на которых основываются многие современные подходы к защите окружающей среды, является так называемая глубинная экология. Термин «глубинная экология» был предложен в 1973 году норвежским философом и экологом Арне Нэссом. Согласно глубинной экологии, необходимо обеспечивать благополучие и процветание не только человека, но и иных форм жизни на Земле, для чего необходимо стремиться не сокращать богатство и разнообразие всех форм жизни. Ученые могут внести и вносят большой вклад в реализации этих принципов.</p><p>Законы</p>